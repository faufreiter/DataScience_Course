{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6e1f607c-8b35-4966-8990-45f87243e4db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\"> Predictive Analysis - Image Processing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "23dd5f65-275b-4dcb-8a9c-e72a01490e1d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Classify handwritten digits using the famous MNIST data\n",
    "\n",
    "The goal of this task is to take an image of a handwritten single digit and determine what digit it is.  \n",
    "\n",
    "The data for this competition was taken from the **MNIST data set**. The MNIST (\"Modified National Institute of Standards and Technology\") data set is a classic within the Machine Learning community that has been extensively studied.  More details about the dataset, including Machine Learning algorithms that have been tried on it and their levels of success, can be found [here](http://yann.lecun.com/exdb/mnist/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0daeed23-218c-4336-9d29-6129d1e6af08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pylab\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b098cb66-77f2-4e25-823e-1aba570fb4af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datapath = os.path.join(os.getcwd(), 'data')\n",
    "print(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4199ada1-a1f6-4842-ba56-bfdff91d39f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read training data from CSV file \n",
    "\n",
    "with ZipFile(os.path.join(datapath, 'kaggle_digits_train.zip'), 'r') as myzip:\n",
    "    with myzip.open('kaggle_digits_train.csv') as myfile:\n",
    "        train_data = pd.read_csv(myfile)\n",
    "        \n",
    "with ZipFile(os.path.join(datapath, 'kaggle_digits_test.zip'), 'r') as myzip:\n",
    "    with myzip.open('kaggle_digits_test.csv') as myfile:\n",
    "        test_data = pd.read_csv(myfile)\n",
    "\n",
    "print('data({0[0]},{0[1]})'.format(train_data.shape))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ffa0a271-6701-4548-b9a1-4d07417bd752",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Every image is a \"stretched\" array of pixel values.\n",
    "In this case it's  28 * 28 = 784 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4ff8aa87-5e9b-428f-8989-0f77a243050c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_size = 4200\n",
    "\n",
    "images = train_data.iloc[:sample_size, 1:].values   # Decreasing the number of images to save memory\n",
    "images = images.astype(np.float16)\n",
    "\n",
    "# convert from [0:255] to [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "print('images numpy array have shape: ({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "11334e40-a29e-4c51-8e4c-8caa5b40c09f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f173d30f-84cb-440d-aa3a-7046b6767bb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_size = images.shape[1]\n",
    "print ('image_size   => {0}'.format(image_size))\n",
    "\n",
    "# in this case all images are square\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "print ('image_width  => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the images in a way that is more comprehensible to the human eye. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3d51f395-dc3d-4f89-a7bb-a0ef78d368d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_TO_DISPLAY = 10\n",
    "#plt.install_repl_displayhook()\n",
    "#plt.imshow(images[IMAGE_TO_DISPLAY].reshape((28, 28)), cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "83145c29-4600-4305-b503-d32f5a1b566a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels_flat = train_data.iloc[:sample_size, 0].values   # Adjusting the number of labels to the number of images selected\n",
    "\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "print ('labels_flat[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6c64d53b-908e-4ac3-a5fc-85b228b55f2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for i in range(0,9):\n",
    "    plt.subplot(250 + (i+1))\n",
    "    img = images[i,:].reshape(28, 28)\n",
    "    plt.imshow(img, cmap='Greys')\n",
    "    plt.title(labels_flat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "befb3a0f-ac9e-4f9c-b4dc-c8ad6d832b07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "print('labels_count => {0}'.format(labels_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ac8e4007-e22d-4907-8bdc-9cd4bb76f031",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b4edd168-5853-480d-b7c6-c1f66bdb3886",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_images = test_data.values.astype(np.float16)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did for all the previously discussed models in the last lessons, we split our data into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "488aa35a-e660-4dc3-a557-cb511852b439",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(images, \n",
    "                                                                    labels_flat, \n",
    "                                                                    test_size=0.4, \n",
    "                                                                    random_state=0)\n",
    "print('train images({0[0]},{0[1]})'.format(X_train.shape))\n",
    "print('validation images({0[0]},{0[1]})'.format(X_test.shape))\n",
    "print('train labels({})'.format(y_train.shape))\n",
    "print('validation labels({})'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eef0d423-139e-490a-abc9-05762d9041f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "del(images)  #save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0be68aaa-137d-4f83-b5e6-b2189a4c63b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create and train the random forest\n",
    "# multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
    "clf_rf = RandomForestClassifier(n_estimators=300, \n",
    "                                criterion='gini', \n",
    "                                max_depth=None, \n",
    "                                min_samples_split=3, \n",
    "                                min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                max_features='auto', \n",
    "                                max_leaf_nodes=None, \n",
    "                                bootstrap=True, \n",
    "                                oob_score=False, \n",
    "                                n_jobs=-1, \n",
    "                                random_state=0, \n",
    "                                verbose=0, \n",
    "                                warm_start=False, \n",
    "                                class_weight=None).fit(X_train, y_train)\n",
    "\n",
    "eval_rf = clf_rf.score(X_test, y_test)\n",
    "print(eval_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "348fdb92-90e5-412e-b70d-da1619826fd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train SVM...\n",
    "from sklearn import svm\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "clf_svm = svm.SVC(kernel='poly',\n",
    "                  C=1.57,\n",
    "                  degree=2, \n",
    "                  gamma=0.278,\n",
    "                  coef0=0.0, \n",
    "                  shrinking=True, \n",
    "                  probability=False, \n",
    "                  tol=0.001, \n",
    "                  cache_size=200, \n",
    "                  class_weight=None, \n",
    "                  verbose=False, \n",
    "                  max_iter=-1, \n",
    "                  random_state=0).fit(X_train, y_train)\n",
    "\n",
    "eval_svm = clf_svm.score(X_test, y_test)\n",
    "print(eval_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d8b54525-8977-49c6-b3dc-17d31c78f4fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "21e79f2d-1e6b-43dd-b740-69780d02ce0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_rf = clf_rf.predict(test_images)\n",
    "predict_rf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2bea3d47-6606-41ad-a42f-bfac8ecd4876",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_svm = clf_svm.predict(test_images)\n",
    "predict_svm[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "20ab3173-a6e7-47a9-b34e-e797aad43b3c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using Tensor Flow (with a fully connected ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d152bd30-a82d-408e-b753-5e8eaa620eae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bf12c54d-8a84-4c4e-8843-6b35a02d5bc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],28,28)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28)\n",
    "y_train = y_train.reshape(y_train.shape[0])\n",
    "y_test = y_test.reshape(y_test.shape[0])\n",
    "\n",
    "print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (X_test.shape, y_test.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2d82ce6-ff5d-4bf3-8243-d8b49f4e5394",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
    "                                   ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "32b41a6a-4a4a-439d-987d-d1ed46f997e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "758af1d3-5476-4785-a574-fdeb9c4ed554",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cde20b88-a60a-44bb-bba9-974a5950b1a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cd2f2b80-e0eb-4780-912f-a10ec7265d4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "76562231-9c65-41b3-9f1c-e711624fdd85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9ab48aad-ebb3-4a8a-942f-b197efcdc9a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using Tensor Flow (with a CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "358a7603-a864-4252-9bcc-868b104d47fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### a) Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "87730485-fea2-4aed-a5f2-ea03e6545b39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reshape dataset to have a single channel\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "#y_train = y_train.reshape(y_train.shape[0])\n",
    "#y_test = y_test.reshape(y_test.shape[0])\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, \n",
    "                                                           kernel_size=(3, 3), \n",
    "                                                           activation='relu', \n",
    "                                                           kernel_initializer='he_uniform', \n",
    "                                                           input_shape=(28, 28, 1)\n",
    "                                                          ),\n",
    "                                    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "                                   ])\n",
    "\n",
    "model.compile(optimizer='adam', #SGD(lr=0.01, momentum=0.9)\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              #loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b18cd835-8e81-4932-a3a8-f4c039d19836",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "556908f2-da5f-4d00-b881-eee03f6ae81c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e22e310b-3968-4378-9936-5c52f3351648",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b0659b6c-5f3a-448e-bcbc-cf6bedfa80ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a00ef0b5-f691-42a9-a637-34b8826ebc3f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### b) Slightly bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "596446d2-a3b8-415c-8ea3-080b8653c1e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d39e9f3b-1b79-4ebc-9dfe-df8fd3964a83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, \n",
    "                                 kernel_size=(3, 3),\n",
    "                                 activation='relu',\n",
    "                                 kernel_initializer='he_uniform',\n",
    "                                 input_shape=(28, 28, 1)\n",
    "                                ))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', #tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "              #loss='categorical_crossentropy',\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "efc5c2ea-c577-46d6-b27b-0f3c1dedb866",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fec545a0-ef0c-4a47-804c-e135849c262d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7473428-e22b-4597-8964-029eed3bed26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "49b18586-8e4e-4c7f-80da-f362d6984b18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "98cd7c6e-0f9b-4a5c-afd7-60d0cd14ee72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.accuracy, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_accuracy, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "763813b1-455f-49ea-b1df-96e75b71f4f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### c) [Using the LENET architecture](https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/  )\n",
    "\n",
    "![](./img/lenet_architecture-768x226.png)\n",
    "\n",
    "The LeNet architecture was first introduced by LeCun et al. in their 1998 paper, Gradient-Based Learning Applied to Document Recognition. As the name of the paper suggests, the authors’ implementation of LeNet was used primarily for OCR and character recognition in documents.  \n",
    "\n",
    "The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs — it can even run on the CPU (if your system does not have a suitable GPU), making it a great “first CNN”.  \n",
    "\n",
    "However, if you do have GPU support and can access your GPU via Keras, you will enjoy extremely fast training times (in the order of 3-10 seconds per epoch, depending on your GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3dbf95a2-fba3-4a9b-b626-b4043daf4994",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Convolution2D(filters=20, kernel_size = (5, 5), padding = \"same\", input_shape = (28, 28, 1)))\n",
    "model.add(tf.keras.layers.Activation(activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides =  (2, 2)))\n",
    "model.add(tf.keras.layers.Convolution2D(filters=50, kernel_size = (5, 5), padding = \"same\"))\n",
    "model.add(tf.keras.layers.Activation(activation= \"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(500))\n",
    "model.add(tf.keras.layers.Activation(activation = \"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', #tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "              #loss='categorical_crossentropy',\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c8add651-a8f7-405a-8151-d4e6a6a39b32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "%time history = model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, \\\n",
    "                          validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "90475f39-3a46-4344-b54a-4e89342aa9a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed2606d9-2764-4d99-b4e4-3d489f987c28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.accuracy, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_accuracy, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1466f1b8-df88-40db-9b21-4e8d235abd0e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### d) Testing a more complex model\n",
    "\n",
    "![](https://sihamtabik.github.io/LeNet-like-CNN.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "01394a3f-0040-489e-9c37-a63a0936c737",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nb_filters_1 = 32 # 64\n",
    "nb_filters_2 = 64 # 128\n",
    "nb_filters_3 = 128 # 256\n",
    "nb_conv = 3\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1,1), input_shape=(28, 28, 1),))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_1, (nb_conv, nb_conv),  activation=\"relu\"))\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_1, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(strides=(2,2)))\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_2, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_2, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(strides=(2,2)))\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.ZeroPadding2D((1, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(nb_filters_3, (nb_conv, nb_conv), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(strides=(2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', #tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "              #loss='categorical_crossentropy',\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fdeaadd3-9d4a-41f0-b341-b1ebc3b1f2bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "49296317-8a02-422a-b23d-a91e9e465ea4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e243a52-7a18-4b4b-9bd1-b2bbb1475825",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "plt.style.use('bmh')\n",
    "params_dict = dict(linestyle='solid', linewidth=0.25, marker='o', markersize=6)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_df.loss, label='Training loss', **params_dict)\n",
    "plt.plot(hist_df.val_loss, label='Validation loss', **params_dict)\n",
    "plt.title('Loss for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_df.accuracy, label='Training accuracy', **params_dict)\n",
    "plt.plot(hist_df.val_accuracy, label='Validation accuracy', **params_dict)\n",
    "plt.title('Accuracy for ' + str(len(history.epoch)) + ' epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "93c6203f-0d9e-4332-92fc-cdd2e9ba4b81",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Pre-trained models  \n",
    "\n",
    "How can I use pre-trained models in Keras?  \n",
    "Code and pre-trained weights are available for the following image classification models:  \n",
    "+ Xception  \n",
    "+ VGG16  \n",
    "+ VGG19  \n",
    "+ ResNet50  \n",
    "+ Inception v3  \n",
    "\n",
    "They can be imported from the module [keras.applications](https://keras.io/applications/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3bf22a9f-212b-49ec-a07a-641cb787cc6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#from tf.keras.applications.xception import Xception\n",
    "#from tf.keras.applications.vgg16 import VGG16\n",
    "#from tf.keras.applications.vgg19 import VGG19\n",
    "#from tf.keras.applications.resnet50 import ResNet50\n",
    "#from tf.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b85b85f3-b10c-4b4b-b970-0343b1b5f9d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Where can i go further?\n",
    "[Transfer Learning and Fine-Tuning](https://keras.io/guides/transfer_learning/)  \n",
    "[Visualizing the classification task](http://scs.ryerson.ca/~aharley/vis/fc/)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1_CNN_Computer_Vision",
   "notebookOrigID": 2649658360539072,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
