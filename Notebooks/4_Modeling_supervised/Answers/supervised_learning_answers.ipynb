{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ho4wyIjNk0mb"
   },
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1618374871754,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "ji40KHgCk0mt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"data_titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2krGzNzk0mw"
   },
   "source": [
    "## Brief Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1618374877676,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "qzKFZq1bk0mx",
    "outputId": "b318d79b-3b8e-47be-e410-3388d848914e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      204      889\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7        4      644"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorical features\n",
    "train.describe(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1618374879814,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "KBNypknXk0m0",
    "outputId": "795cadfb-6ba7-4a87-a3e8-d13dc237c305"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numerical features\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7WCfHHzk0m1"
   },
   "source": [
    "Let's work only with the following for simplicity\n",
    "Categorical:\n",
    "- Sex\n",
    "- Embarked\n",
    "\n",
    "Numerical:\n",
    "- Survived: *target* 0 = No, 1 = Yes\n",
    "- Pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- Age: Age in years\n",
    " \n",
    "More detailed info: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1618374883434,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "sd2M3lHQk0m2"
   },
   "outputs": [],
   "source": [
    "#Let's keep only the desired columns\n",
    "train = train[['Sex','Embarked','Pclass', 'Age','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1618374887369,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "3Ka0DLdTk0m3",
    "outputId": "2c8a012f-08bd-4524-dc84-26f6c091ed7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1618374888749,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "cHLemKl1k0m4",
    "outputId": "dfcb7341-9c35-4521-bdb5-75aa2164e48d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex           0\n",
       "Embarked      2\n",
       "Pclass        0\n",
       "Age         177\n",
       "Survived      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgbZZoa7k0m5"
   },
   "source": [
    "For simplicity, we drop rows with missing values. If you will later experiment with composite transformers, comment out this cell so that you try to include also missing value imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1618374892058,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "n18Aaofzk0m6"
   },
   "outputs": [],
   "source": [
    "train = train.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex Embarked  Pclass   Age  Survived\n",
       "0    male        S       3  22.0         0\n",
       "1  female        C       1  38.0         1\n",
       "2  female        S       3  26.0         1\n",
       "3  female        S       1  35.0         1\n",
       "4    male        S       3  35.0         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPSNoOLBk0m6"
   },
   "source": [
    "## Feature Engineering\n",
    "With our current knowledge, we can try to implement individually various transformers from scikit-learn. Let's not forget to create a holdout set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1186,
     "status": "ok",
     "timestamp": 1618374902835,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "xESayijIk0m7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[['Pclass', 'Age', 'Sex', 'Embarked']],\n",
    "                                                    train['Survived'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7D0fIZYk0m8"
   },
   "source": [
    "### Numerical Features\n",
    "- Pclass\n",
    "- Age  \n",
    "Let's just scale these two features using MinMax scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1618374904389,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "m9kbMJCSk0m8",
    "outputId": "09545a75-2b3c-43b6-ad2b-19ed5a73c7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 2)\n",
      "(143, 2)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train[['Pclass', 'Age']])\n",
    "X_train_transformed_numerical = scaler.transform(X_train[['Pclass', 'Age']])\n",
    "X_test_transformed_numerical = scaler.transform(X_test[['Pclass', 'Age']])\n",
    "\n",
    "print(X_train_transformed_numerical.shape)\n",
    "print(X_test_transformed_numerical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFttk2tTk0m9"
   },
   "source": [
    "### Categorical Features\n",
    "*   Sex\n",
    "*   Embarked\n",
    "\n",
    "We can simply one-hot encode these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1618374907682,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "GHS0H6b-k0m-",
    "outputId": "ae61e64e-b6ef-437b-ebc0-45f588051fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 5)\n",
      "(143, 5)\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "encoder.fit(X_train[['Sex', 'Embarked']])\n",
    "X_train_transformed_categorical = encoder.transform(X_train[['Sex', 'Embarked']])\n",
    "X_test_transformed_categorical = encoder.transform(X_test[['Sex', 'Embarked']])\n",
    "\n",
    "print(X_train_transformed_categorical.shape)\n",
    "print(X_test_transformed_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxxpz6Bpk0m_"
   },
   "source": [
    "## HANDS-ON 1: Baseline Model & Model Evaluation\n",
    "Time for first exercise! At first, let's put together the transformed numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1618374916364,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "px3uj8Qbk0m_",
    "outputId": "10f85d2a-7e31-4d66-a979-0600d9897b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 7)\n",
      "(143, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = np.concatenate((X_train_transformed_numerical,X_train_transformed_categorical), axis = 1)\n",
    "X_test_transformed = np.concatenate((X_test_transformed_numerical,X_test_transformed_categorical), axis = 1)\n",
    "\n",
    "print(X_train_transformed.shape)\n",
    "print(X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1618374971330,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "bkroeCgrk0nA"
   },
   "outputs": [],
   "source": [
    "# TASK 1: Fit sklearn.DummyClassifier. Then, let the model predict for train (X_train_transformed) and holdout set(X_test_transformed).\n",
    "# Store the prediction as y_pred_TRAIN_DUMMY (training set) and as y_pred_HOLDOUT_DUMMY (holdout set)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_TRAIN_DUMMY = dummy_clf.predict(X_train_transformed)\n",
    "y_pred_HOLDOUT_DUMMY = dummy_clf.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tySjhxbZk0nA"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL TASK 1: Think about a simple heuristic that can be used as baseline. \n",
    "# One possibility is to use gender and for example predict that every men or every woman has survived.\n",
    "# You can store the result as y_pred_TRAIN_HEURISTIC and as y_pred_HOLDOUT_HEURISTIC.\n",
    "\n",
    "y_pred_TRAIN_HEURISTIC = np.array([1 if idx==0 else 0 for idx in X_train_transformed[:,3]])\n",
    "y_pred_HOLDOUT_HEURISTIC =np.array([1 if idx==0 else 0 for idx in X_test_transformed[:,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4Cvwakdk0nB"
   },
   "source": [
    "Great! We have our first prediction! It is time to evaluate how good our (poor dummy) model is. It is time to use the *sklearn.metrics* module.   \n",
    "https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1618375004083,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "zZ8NJe0sk0nC",
    "outputId": "44e7e03c-d5dd-4b41-b982-499fe0e741d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6045694200351494\n",
      "0.7873462214411248\n",
      "\n",
      "0.5594405594405595\n",
      "0.7482517482517482\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#TASK 2A: Display ACCURACY on TRAIN set.\n",
    "print(metrics.accuracy_score(y_train, y_pred_TRAIN_DUMMY))\n",
    "print(metrics.accuracy_score(y_train,y_pred_TRAIN_HEURISTIC))  #Optional Task 1\n",
    "print()\n",
    "#TASK 2B: Display ACCURACY on HOLDOUT set.\n",
    "print(metrics.accuracy_score(y_test, y_pred_HOLDOUT_DUMMY))\n",
    "print(metrics.accuracy_score(y_test, y_pred_HOLDOUT_HEURISTIC))  #Optional Task 1\n",
    "\n",
    "#OPTIONAL TASK 2C: Can you think of better measure than accuracy based on the domain problem? If yes, use it the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0z-ujkVk0nC"
   },
   "source": [
    "Great, now we would also like to see confusion matrix as it is always a good idea to see visually the quality of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1618375239316,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "jmVEXZBCk0nC",
    "outputId": "88972c29-dfe1-440b-b8bb-6d998f0f4677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80,  0],\n",
       "       [63,  0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TASK 3: Display a CONFUSION MATRIX on HOLDOUT set. Hint: do not use plot_confusion_matrix but confusion_matrix only.\n",
    "metrics.confusion_matrix(y_test, y_pred_HOLDOUT_DUMMY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68, 12],\n",
       "       [24, 39]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_HOLDOUT_HEURISTIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTrQnvV5k0nD"
   },
   "source": [
    "## HANDS-ON 2: Composite Estimators\n",
    "Let's nicely wrap our Feature Engineering and model fitting into a nice composite estimator. We will be very simplistic and only use two  \n",
    "They will not nest into each other at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2qkLyyjk0nD"
   },
   "source": [
    "### Feature Engineering wrapped into ColumnTransformer\n",
    "The two feature transformations can be easily wrapped up into a single ColumnTransformer. This will ensure that our Feature Engineering is a **bit more robust and nicely encapsulated**. Refer to the section 6.1.4 of the following link. It will showcase the exact application that we intend to create:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1618375452991,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "sCx1ZHutk0nE"
   },
   "outputs": [],
   "source": [
    "#TASK 3: Wrap MinMaxScaler and OneHotEncoder into a single ColumnTransformer. The transformers should be applied to according columns only.\n",
    "#Store the resulting composite as feature_engineering\n",
    "# Hint: use argument remainder='passthrough'\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "feature_engineering = ColumnTransformer([('numerical_scaler', preprocessing.MinMaxScaler(),['Pclass', 'Age']),\n",
    "                                         ('ohe', preprocessing.OneHotEncoder(sparse=False), ['Sex', 'Embarked'])\n",
    "                                        ],\n",
    "                                        remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mfU_j3Bk0nE"
   },
   "source": [
    "### Predictive Model Wrapped into Pipeline\n",
    "Let's now wrap together feature engineering with the model into a single Pipeline Composite estimator. Here is a pseudocode:\n",
    "- entire_pipeline = feature_engineering -> model  \n",
    "\n",
    "Both components are already available. From step above, we can directly reuse the object feature_engineering. As model, we just call new DummyClassifier, just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1618375619490,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "QeHFs8Mek0nF"
   },
   "outputs": [],
   "source": [
    "# TASK 4: Wrap Feature Engineering and Predictive Model (dummy) into a single Pipeline composite estimator. \n",
    "# Store the result as entire_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "entire_pipeline = Pipeline([('feature_engineering', feature_engineering), ('dummy', DummyClassifier(strategy=\"most_frequent\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1618375706973,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "4yaNiSrltFVP",
    "outputId": "891f9e6d-dacb-4d9a-831a-6656226af834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerical_scaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['Pclass', 'Age']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['Sex', 'Embarked'])])),\n",
       "                ('dummy', DummyClassifier(strategy='most_frequent'))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK: Uncomment the line and try to train the pipeline.\n",
    "# It should not return an error. \n",
    "# Notice that we are using untransformed data again (X_train) as the pipeline contains the transformers.\n",
    "\n",
    "entire_pipeline.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1618375919025,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "mNMnLojMtoiC",
    "outputId": "bff6660c-7a04-4db2-f69f-919c31046153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6045694200351494\n",
      "0.5594405594405595\n"
     ]
    }
   ],
   "source": [
    "#Predict for training data\n",
    "y_pred_TRAIN_DUMMY = entire_pipeline.predict(X_train)\n",
    "\n",
    "#Predict for holdout data\n",
    "y_pred_HOLDOUT_DUMMY = entire_pipeline.predict(X_test)\n",
    "\n",
    "#Results should be the same as before\n",
    "print(metrics.accuracy_score(y_train, y_pred_TRAIN_DUMMY))\n",
    "\n",
    "#TASK 2B: Display ACCURACY on HOLDOUT set.\n",
    "print(metrics.accuracy_score(y_test, y_pred_HOLDOUT_DUMMY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFtyCYGWk0nF"
   },
   "source": [
    "OPTIONAL TASK:   \n",
    "A notebook 'nice_pipeline' was made to exemplify some examples of more complex pipelines. Feel free to scroll through it and learn how a process of preparing a complex composite looks like. You can then come back here and try to implement various components. For example, if I would not drop rows with missing values at the beginning of this notebook, constructing a composite would get a bit trickier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Aui4V07k0nG"
   },
   "source": [
    "## HANDS-ON 3: Tree-based Models & Hyperparameter Tuning\n",
    "Hold your constructed Pipeline firmly! The only thing that we need to do now, is to replace the DummyClassifier with a proper learning model. We can start by a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQpLSIHgk0nG"
   },
   "source": [
    "### Fitting Learning Model - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1618376076145,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "Qw-kQjzok0nG",
    "outputId": "578a6350-2b29-48fd-a607-3a88a65b272a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerical_scaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['Pclass', 'Age']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['Sex', 'Embarked'])])),\n",
       "                ('decision_tree', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK 5: Reuse your composite, instead of a dummy, fit a decision tree with default parameters.\n",
    "# Store the result as dt_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_pipeline = Pipeline([('feature_engineering', feature_engineering), ('decision_tree', DecisionTreeClassifier())])\n",
    "\n",
    "# Train the pipeline\n",
    "dt_pipeline.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1618376463480,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "qN8mjWwok0nH",
    "outputId": "817169d5-80ff-48b0-a81a-2146539704cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209138840070299\n"
     ]
    }
   ],
   "source": [
    "# TASK 5B: Let the pipeline predict for TRAINING set. Store the result as y_pred_TRAIN_DT\n",
    "# Also, Display accuracy.\n",
    "\n",
    "y_pred_TRAIN_DT = dt_pipeline.predict(X_train)\n",
    "print(metrics.accuracy_score(y_train, y_pred_TRAIN_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1618376518224,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "O9JQW5Tok0nH",
    "outputId": "f342f8af-f07a-4f65-e4c1-36ee6dc67c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552447552447552\n"
     ]
    }
   ],
   "source": [
    "# TASK 5C: Let the pipeline predict for HOLDOUT set. Store the result as y_pred_HOLDOUT_DT\n",
    "# Also, Display accuracy.\n",
    "\n",
    "y_pred_HOLDOUT_DT = dt_pipeline.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_HOLDOUT_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYn8-Bx-k0nI"
   },
   "source": [
    "Looking at the accuracy on training and holdout set, what can you infer about over model? Will it generalize well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2297,
     "status": "ok",
     "timestamp": 1618376658900,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "o5ghSRY7k0nI",
    "outputId": "a271453e-1743-48c7-9c4d-5e5077791d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209138840070299\n",
      "0.7832167832167832\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL TASK 6: Do the same steps with RandomForest with default parameters. \n",
    "# Does the RandomForest display similar results as decision tree? If not, why?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipeline = Pipeline([('feature_engineering', feature_engineering), ('random_forest', RandomForestClassifier())])\n",
    "\n",
    "# Train the pipeline\n",
    "rf_pipeline.fit(X = X_train, y = y_train)\n",
    "\n",
    "#Predict and show accuracy TRAIN\n",
    "y_pred_TRAIN_RF = rf_pipeline.predict(X_train)\n",
    "print(metrics.accuracy_score(y_train, y_pred_TRAIN_RF))\n",
    "\n",
    "#Predict and show accuracy HOLDOUT\n",
    "y_pred_HOLDOUT_RF = rf_pipeline.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_HOLDOUT_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C48pxfJak0nI"
   },
   "source": [
    "### Tuning Hyperparameters of our Decision Tree\n",
    "Time to improve the performance of our learning model by finding its optimal set of hyperparameters.  \n",
    "We start by examining **what hyperparameters are available** in our decision tree pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1618377108933,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "QxSoArYeyUHp",
    "outputId": "8aaa62f8-2915-4d14-f4f9-e3c01819606a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('feature_engineering',\n",
       "   ColumnTransformer(remainder='passthrough',\n",
       "                     transformers=[('numerical_scaler', MinMaxScaler(),\n",
       "                                    ['Pclass', 'Age']),\n",
       "                                   ('ohe', OneHotEncoder(sparse=False),\n",
       "                                    ['Sex', 'Embarked'])])),\n",
       "  ('decision_tree', DecisionTreeClassifier())],\n",
       " 'verbose': False,\n",
       " 'feature_engineering': ColumnTransformer(remainder='passthrough',\n",
       "                   transformers=[('numerical_scaler', MinMaxScaler(),\n",
       "                                  ['Pclass', 'Age']),\n",
       "                                 ('ohe', OneHotEncoder(sparse=False),\n",
       "                                  ['Sex', 'Embarked'])]),\n",
       " 'decision_tree': DecisionTreeClassifier(),\n",
       " 'feature_engineering__n_jobs': None,\n",
       " 'feature_engineering__remainder': 'passthrough',\n",
       " 'feature_engineering__sparse_threshold': 0.3,\n",
       " 'feature_engineering__transformer_weights': None,\n",
       " 'feature_engineering__transformers': [('numerical_scaler',\n",
       "   MinMaxScaler(),\n",
       "   ['Pclass', 'Age']),\n",
       "  ('ohe', OneHotEncoder(sparse=False), ['Sex', 'Embarked'])],\n",
       " 'feature_engineering__verbose': False,\n",
       " 'feature_engineering__verbose_feature_names_out': True,\n",
       " 'feature_engineering__numerical_scaler': MinMaxScaler(),\n",
       " 'feature_engineering__ohe': OneHotEncoder(sparse=False),\n",
       " 'feature_engineering__numerical_scaler__clip': False,\n",
       " 'feature_engineering__numerical_scaler__copy': True,\n",
       " 'feature_engineering__numerical_scaler__feature_range': (0, 1),\n",
       " 'feature_engineering__ohe__categories': 'auto',\n",
       " 'feature_engineering__ohe__drop': None,\n",
       " 'feature_engineering__ohe__dtype': numpy.float64,\n",
       " 'feature_engineering__ohe__handle_unknown': 'error',\n",
       " 'feature_engineering__ohe__sparse': False,\n",
       " 'decision_tree__ccp_alpha': 0.0,\n",
       " 'decision_tree__class_weight': None,\n",
       " 'decision_tree__criterion': 'gini',\n",
       " 'decision_tree__max_depth': None,\n",
       " 'decision_tree__max_features': None,\n",
       " 'decision_tree__max_leaf_nodes': None,\n",
       " 'decision_tree__min_impurity_decrease': 0.0,\n",
       " 'decision_tree__min_samples_leaf': 1,\n",
       " 'decision_tree__min_samples_split': 2,\n",
       " 'decision_tree__min_weight_fraction_leaf': 0.0,\n",
       " 'decision_tree__random_state': None,\n",
       " 'decision_tree__splitter': 'best'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ6o3OUCy8wB"
   },
   "source": [
    "We would like to tune max_depth and min_samples_split.  \n",
    "Notice that to access them, we also need to navigate within the composite and call them as *decision_tree__max_depth*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1618377645004,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "R10ez3ySk0nJ"
   },
   "outputs": [],
   "source": [
    "# TASK 7: Define a grid through which we should search. Tune parameters: max_depth and min_samples_split.\n",
    "# The values which you pick for parameters are up to you. You can think about them intuitively.\n",
    "\n",
    "param_grid = {'decision_tree__max_depth':[3, 4, 5, 6, 7, 8, 9], \n",
    "              'decision_tree__min_samples_split':[ 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4854,
     "status": "ok",
     "timestamp": 1618377651214,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "QPKhg8T6k0nJ",
    "outputId": "8d47f4c2-0b3d-41c5-b020-41dc0867cdd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('feature_engineering',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('numerical_scaler',\n",
       "                                                                         MinMaxScaler(),\n",
       "                                                                         ['Pclass',\n",
       "                                                                          'Age']),\n",
       "                                                                        ('ohe',\n",
       "                                                                         OneHotEncoder(sparse=False),\n",
       "                                                                         ['Sex',\n",
       "                                                                          'Embarked'])])),\n",
       "                                       ('decision_tree',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             param_grid={'decision_tree__max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
       "                         'decision_tree__min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 15, 20,\n",
       "                                                              25]})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Model\n",
    "dt_pipeline\n",
    "\n",
    "#Searching strategy, providing grid\n",
    "tuning = GridSearchCV(dt_pipeline, param_grid)\n",
    "\n",
    "#Train\n",
    "tuning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1618377655915,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "83CfJwuozR8p",
    "outputId": "8802065d-d9cc-495a-eab0-a51d13be8108"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision_tree__max_depth': 6, 'decision_tree__min_samples_split': 5}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get the best parameters\n",
    "tuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1618377616146,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "8Fl4UVR9k0nJ",
    "outputId": "4fe7d719-b8fa-4009-e730-c9acf6c33823"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerical_scaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['Pclass', 'Age']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['Sex', 'Embarked'])])),\n",
       "                ('decision_tree',\n",
       "                 DecisionTreeClassifier(max_depth=6, min_samples_split=5))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK 8: Use the best setting of the two hyperparameters and fit a optimized decision tree. Hint: Reuse the pipeline, just when declaring it, specify the params.\n",
    "# Store it as dt_pipeline_tuned\n",
    "\n",
    "dt_pipeline_tuned = Pipeline([('feature_engineering', feature_engineering), \n",
    "                              ('decision_tree', DecisionTreeClassifier(max_depth=6, min_samples_split=5))])\n",
    "\n",
    "# Train\n",
    "dt_pipeline_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1618377619616,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "T7GNUdWTk0nK",
    "outputId": "cb944eca-7c5f-4265-9f43-d90acefa4bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8506151142355008\n"
     ]
    }
   ],
   "source": [
    "# TASK 8B: Display accuracy on TRAINING set of the optimized decision tree.\n",
    "\n",
    "print(metrics.accuracy_score(y_train, dt_pipeline_tuned.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1618377620888,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "bpYLJ1q2k0nK",
    "outputId": "bb9813ef-ee82-4978-a74d-d14120e193c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7342657342657343\n"
     ]
    }
   ],
   "source": [
    "# TASK 8C: Display accuracy on HOLDOUT set of the optimized decision tree.\n",
    "print(metrics.accuracy_score(y_test, dt_pipeline_tuned.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgVkGV9qk0nK"
   },
   "source": [
    "Does the optimized decision tree perform better then the one with default parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dddsxUaYk0nL"
   },
   "source": [
    "### Optional Advanced TASK: Tuning Random Forest\n",
    "When you are tuning a more complex model, it is a good practice to search available literature on which hyperparameters should be tuned. Below I have predefined some. You can play around with the grid, for example expand or narrow it. Keep in mind that as our feature set is extremely limited, its hard for hyperparameter tuning to arrive to something meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 168327,
     "status": "ok",
     "timestamp": 1618378569236,
     "user": {
      "displayName": "Robert Barcik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgV4kbB-8oZS-p-vhI2xma0v0GgvlaFuZ5ZLU_nvG8=s64",
      "userId": "12944327394729832066"
     },
     "user_tz": -120
    },
    "id": "pa-zPU0gk0nL",
    "outputId": "958dbb7c-0250-4da9-8c50-0ab7712b2af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8137866790870982\n",
      "{'random_forest__bootstrap': True, 'random_forest__max_depth': 15, 'random_forest__max_features': 2, 'random_forest__min_samples_leaf': 3, 'random_forest__min_samples_split': 10, 'random_forest__n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL TASK 9\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define a pipeline\n",
    "rf_pipeline = Pipeline([('feature_engineering', feature_engineering), ('random_forest', RandomForestClassifier())])\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid_rf = {\n",
    "    'random_forest__bootstrap': [True, False],\n",
    "    'random_forest__max_depth': [3, 5, 10, 15],\n",
    "    'random_forest__max_features': [2, 3],\n",
    "    'random_forest__min_samples_leaf': [3, 4, 5],\n",
    "    'random_forest__min_samples_split': [5, 8, 10, 12],\n",
    "    'random_forest__n_estimators': [5, 10, 15, 20, 25]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf_pipeline, \n",
    "                           param_grid = param_grid_rf, \n",
    "                           cv = 3, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "#Searching strategy, providing grid\n",
    "tuning_rf = GridSearchCV(rf_pipeline, param_grid_rf)\n",
    "\n",
    "#Train\n",
    "tuning_rf.fit(X_train, y_train)\n",
    "\n",
    "#Cross-validated score (more robust than holdout set most likely)\n",
    "print(tuning_rf.best_score_)\n",
    "print(tuning_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6doV7qmH1HUp"
   },
   "source": [
    "### Optional Advanced TASK: Check Kaggle competitions and join one of them!  \n",
    "https://www.kaggle.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "supervised_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
